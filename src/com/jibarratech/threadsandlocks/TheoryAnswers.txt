What's the difference between a thread and a process?

Processes and threads are related to each other but are fundamentally different.

A process can be thought of as an instance of a program in execution. A proces is an
independent entity to which system resources (e.g., CPU time and memory) are allocated.
Each process is executed in a separate address space, and one process cannot
access the variables and data structures of another process. If a process wishes to access
another process' resources, inter-process communications have to be used. These
include pipes, files, sockets, and other forms.

A thread exists within a process and shares the process' resources (including its heap
space). Multiple threads within the same process will share the same heap space. This
is very different from processes, which cannot directly access the memory of another
process. Each thread still has its own registers and its own stack, but other threads can
read and write the heap memory.

A thread is a particular execution path of a process. When one thread modifies a process
resource, the change is immediately visible to sibling threads.


How would you measure the time spent in a context switch?

A context switch is the time spent switching between two processes (i.e., bringing a waiting process into execution and sending an executing process into waiting/terminated state). This happens in multitasking. The operating system must bring the state information of waiting processes into memory and save the state information of the currently running process.
In order to solve this problem, we would like to record the timestamps of the last and first instruction of the swapping processes. The context switch time is the difference in the timestamps between the two processes.
Let's take an easy example: Assume there are only two processes, P1 and P2.
P1 is executing and P2 is waiting for execution. At some point, the operating system must swap P1 and P2â€”let's assume it happens at the Nth instruction of P1. If t x,k indicates the timestamp in microseconds of the kth instruction of process x, then the context switch would take t 2,1 - t 1,n microseconds.
The tricky part is this: how do we know when this swapping occurs? We cannot, of course, record the timestamp of every instruction in the process.
Another issue is that swapping is governed by the scheduling algorithm of the operating system and there may be many kernel level threads which are also doing context switches. Other processes could be contending for the CPU or the kernel handling interrupts. The user does not have any control over these extraneous context switches. For instance, if at time t 1,n the kernel decides to handle an interrupt, then the context switch time would be overstated.
In order to overcome these obstacles, we must first construct an environment such that after P1 executes, the task scheduler immediately selects P2 to run. This may be accomplished by constructing a data channel, such as a pipe, between P1 and P2 and having the two processes play a game of ping-pong with a data token.
That is,let's allow P1 to be the initial sender and P2 to be the receiver. Initially, P2 is blocked (sleeping) as it awaits the data token. When P1 executes, it delivers the token over the data channel to P2 and immediately attempts to read a response token. However, since P2 has not yet had a chance to run, no such token is available for Pa and the process is blocked. This relinquishes the CPU.
A context switch results and the task scheduler must select another process to run. Since P2 is now in a ready-to-run state, it is a desirable candidate to be selected by the task scheduler for execution. When P2 runs, the roles of P1 and P2 are swapped. P2 is now acting as the sender and P1 as the blocked receiver.The game ends when P2 returns the token to P1.
To summarize, an iteration of the game is played with the following steps:
1. P2 blocks awaiting data from P1.
2. P1 marks the start time.
3. P1 sends token to P2.
4. P1 attempts to read a response token from P2.This induces a context switch.
5. P2 is scheduled and receives the token.
6. P2 sends a response token to P1.
7. P2 attempts read a response token from P1. This induces a context switch.
8. P1 is scheduled and receives the token.
9. P1 marks the end time.
The key is that the delivery of a data token induces a context switch. Let Td and Tr be the time it takes to deliver and receive a data token, respectively, and let Tc be the amount of time spent in a context switch. At step 2, P1 records the timestamp of the delivery of the token, and at step 9, it records the timestamp of the response.The amount of time elapsed, T, between these events may be expressed by:
T = 2 * (Td + Tc + Tr)
This formula arises because of the following events: P1 sends a token (3), the CPU context switches (4), P2 receives it (5). P2 then sends the response token (6), the CPU context switches (7), and finally P1 receives it (8).
P1 will be able to easily compute T, since this is just the time between events 3 and 8. So, to solve for Tc,we must first determine the value of Td + Tp.
How can we do this? We can do this by measuring the length of time it takes P1 to send and receive a token to itself. This will not induce a context switch since P1 is running on the CPU at the time it sent the token and will not block to receive it
The game is played a number of iterations to average out any variability in the elapsed time between steps 2 and 9 that may result from unexpected kernel interrupts and additional kernel threads contending for the CPU.We select the smallest observed context switch time as our final answer.
However, all we can ultimately say that this is an approximation which depends on the underlying system. For example, we make the assumption that P2 is selected to run once a data token becomes available. However, this is dependent on the implementation of the task scheduler and we cannot make any guarantees.
That's okay; it's important in an interview to recognize when your solution might not be perfect.